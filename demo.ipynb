{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493adc05",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install -q torchdiffeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2b0ad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from torchdiffeq import odeint\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Setup and Data ---\n",
    "# Use a simple 2D dataset to visualize the process easily.\n",
    "# The \"two moons\" dataset is a classic choice for generative models.\n",
    "X, _ = make_moons(n_samples=2000, noise=0.05)\n",
    "target_data = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "# --- 2. The Neural Network (Vector Field) ---\n",
    "# This network will learn the vector field v(x, t).\n",
    "# It takes a point 'x' (2 dims) and a time 't' (1 dim) as input,\n",
    "# and outputs a vector (2 dims).\n",
    "class VectorField(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        # The network needs to process both the data dimension and the time dimension.\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim + 1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # We need to reshape t to concatenate it with x.\n",
    "        # t is a scalar, so we expand it to the same batch size as x.\n",
    "        t_vec = t.expand(x.size(0), 1)\n",
    "        # Concatenate the spatial and time dimensions.\n",
    "        xt = torch.cat([x, t_vec], dim=1)\n",
    "        return self.network(xt)\n",
    "\n",
    "# --- 3. The Flow Matching Loss ---\n",
    "# This function implements the loss from Step 3 of our discussion.\n",
    "def flow_matching_loss(model, x1, x0=None):\n",
    "    \"\"\"\n",
    "    Calculates the Flow Matching loss.\n",
    "    Args:\n",
    "        model: The neural network that models the vector field.\n",
    "        x1: A batch of real data samples (the target).\n",
    "        x0: A batch of noise samples (the source). If None, will be sampled internally.\n",
    "    \"\"\"\n",
    "    # Sample the source distribution (standard Gaussian noise)\n",
    "    if x0 is None:\n",
    "        x0 = torch.randn_like(x1)\n",
    "\n",
    "    # Sample a random time t from Uniform(0, 1)\n",
    "    t = torch.rand(x1.size(0), 1)\n",
    "\n",
    "    # Calculate the point on the path xt using linear interpolation (Step 1)\n",
    "    xt = (1 - t) * x0 + t * x1\n",
    "\n",
    "    # Define the true velocity vector (the \"instruction\" from Step 2)\n",
    "    ut = x1 - x0\n",
    "\n",
    "    # Get the model's predicted velocity at xt and t\n",
    "    vt = model(xt, t)\n",
    "\n",
    "    # Calculate the mean squared error between the predicted and true velocities\n",
    "    loss = torch.mean((vt - ut)**2)\n",
    "    return loss\n",
    "\n",
    "# --- 4. The Training Loop ---\n",
    "def train_model(data, model, epochs=5000, batch_size=256, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Trains the VectorField model.\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get a random batch of data from the target distribution\n",
    "        indices = torch.randint(0, len(data), (batch_size,))\n",
    "        x1_batch = data[indices]\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = flow_matching_loss(model, x1_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "# --- 5. Generation (Inference) ---\n",
    "# This function uses the trained model to generate new samples (Step 4).\n",
    "def generate_samples(model, num_samples=1000):\n",
    "    \"\"\"\n",
    "    Generates new samples by solving the ODE from t=0 to t=1.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # 1. Start with random noise (the source)\n",
    "        x0 = torch.randn(num_samples, 2)\n",
    "\n",
    "        # 2. Define the ODE function for the solver.\n",
    "        # The solver needs a function that takes (t, x) and returns dx/dt.\n",
    "        # Our model v(x, t) is exactly that function.\n",
    "        def ode_func(t, x):\n",
    "            # The ODE solver passes t as a float, so we need to convert it\n",
    "            # to a tensor of the correct shape for our model.\n",
    "            t_tensor = torch.full((x.size(0), 1), t.item())\n",
    "            return model(x, t_tensor)\n",
    "\n",
    "        # 3. Define the time span for the integration\n",
    "        t_span = torch.tensor([0.0, 1.0])\n",
    "\n",
    "        # 4. Solve the ODE.\n",
    "        # 'odeint' integrates the 'ode_func' from t=0 to t=1, starting from x0.\n",
    "        # The result will be a tensor of shape (time_points, batch_size, dims).\n",
    "        # We only care about the final point at t=1.\n",
    "        generated_x = odeint(ode_func, x0, t_span)[-1]\n",
    "\n",
    "    return generated_x.cpu().numpy()\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == '__main__':\n",
    "    # Instantiate the model\n",
    "    flow_model = VectorField()\n",
    "\n",
    "    # --- Visualize the initial state ---\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(target_data[:, 0], target_data[:, 1], s=10, alpha=0.5, label='Target Data (Two Moons)')\n",
    "    noise = torch.randn(1000, 2)\n",
    "    plt.scatter(noise[:, 0], noise[:, 1], s=10, alpha=0.5, c='r', label='Source Noise (Gaussian)')\n",
    "    plt.title('Before Training')\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.legend()\n",
    "    plt.axis('equal')\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    train_model(target_data, flow_model)\n",
    "\n",
    "    # Generate new samples using the trained model\n",
    "    generated_data = generate_samples(flow_model, num_samples=2000)\n",
    "\n",
    "    # --- Visualize the final result ---\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(target_data[:, 0], target_data[:, 1], s=10, alpha=0.2, label='Target Data (for reference)')\n",
    "    plt.scatter(generated_data[:, 0], generated_data[:, 1], s=10, alpha=0.5, c='g', label='Generated Data')\n",
    "    plt.title('After Training')\n",
    "    plt.xlabel('X1')\n",
    "    plt.legend()\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Visualize the learned vector field (optional) ---\n",
    "    # Create a grid of points\n",
    "    x = np.linspace(-2, 3, 30)\n",
    "    y = np.linspace(-1.5, 2, 30)\n",
    "    X_grid, Y_grid = np.meshgrid(x, y)\n",
    "    points = torch.tensor(np.vstack([X_grid.ravel(), Y_grid.ravel()]).T, dtype=torch.float32)\n",
    "\n",
    "    # Get the vector field at t=0.5\n",
    "    with torch.no_grad():\n",
    "        t_mid = torch.tensor(0.5)\n",
    "        vectors = flow_model(points, t_mid).cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(target_data[:, 0], target_data[:, 1], s=10, alpha=0.1)\n",
    "    plt.quiver(points[:, 0], points[:, 1], vectors[:, 0], vectors[:, 1], color='r', alpha=0.6)\n",
    "    plt.title('Learned Vector Field at t=0.5')\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
